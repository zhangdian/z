# 2013-03-27-rabbitmq

###RabbitMQ
RabbitMQ是一个消息代理，它接收和转发消息。它有六种模式，下面介绍其中的四种模式。

<!-- more -->

####1. 最简单的模式
{% img https://dl.dropbox.com/u/99113526/blog.bd17kaka.net/rabbitmq-1.png %}

#####1.1 角色
* 生产者(Producing)除了发送消息之外，什么也不做，用“P”表示；
* 所有消息都存储在Queue里面，所有消息都流经Queue以及我们的应用程序。Queue没有任何限制，它可以存储尽可能多的消息，本质上，它是一个无穷大(infinite)的buffer；
* 消费者(Consumer)等待接收消息，用“C”表示。

这三个角色没必要在一个机器上，实际上也是这样的。

#####1.2 生产者
生产者发送消息的时候，一定要保证Queue的存在，如果它发送消息到一个不存在的Queue，RabbitMQ会丢弃掉这个消息。

```
channel.queue_declare(queue='hello')
```

RabbitMQ中，消息实际上不会直接发送到Qeueu上，而是先发送到Exchange上，不指定Exchange的话，会发送到默认的Exchange（“”，空字符串）上。

需要在routing_key参数中指定Queue的名称：

```
channel.basic_publish(exchange='',
                      routing_key='hello',
                      body='Hello World!')print " [x] Sent 'Hello World!'"
```

退出之前，需要确保清空缓存，并且所有的消息都发送到RabbitMQ：

```
connection.close()
```

#####1.3 消费者
首先要连接到服务器，其次，要保证Queue的存在，使用queue_declare创建Queue是幂等的（idempotent，也就是多次创建，只会有一个同一名字的Queue被创建），所以，重新声明一个Queue永远是比较好的。

```
channel.queue_declare(queue='hello')
```

RabbitMQ通过注册一个回调函数来接收消息，每次接收到一个消息的时候，都会调用回调函数。其次，需要指定消费者从指定的Queue来接收消息：

```
def callback(ch, method, properties, body):
    print " [x] Received %r" % (body,)

channel.basic_consume(callback,
                      queue='hello',
                      no_ack=True)
```

为了保证正确的读取消息，要保证Queue的存在，只要我们在生产者端创建了Queue，那么就可以保证这点。

然后，就会进入到一个永远都不会停止的循环，只要有消息都会调用回调函数。

####2. One producer, multi consumer
{% img https://dl.dropbox.com/u/99113526/blog.bd17kaka.net/rabbitmq-2.png %}

这种模型用于在众多的Workers之间分发一些耗时的任务。

这种模型的主要思想是：避免立即执行资源密集型的任务，等待其完成。而是将任务压缩成一个消息，将其发送到queue。Worker在后台获取这些任务，然后执行它们。如果允许多个Worker，那么它们会公平的分享这些消息。

这个模型特别适合：在一个短的HTTP周期内完成一个很复杂任务的应用。

#####2.1 Round-robin dispatching(轮询调度)
这种模型很容易做到平衡工作调度。如果突然多了很多的消息，那么可以添加更多的Worker来解决，很容易扩展。

默认情况下，RabbitMQ会按顺序的，将每个消息分发给下一个consumer，平均来看，每个consumer会获得相同数目的消息。这种分发消息的模式叫做Round-robin。

#####2.2 Message ACK
当一个worker开始一个耗时的task，但是在执行了一部分的时候失败了。对于当前的RabbitMQ的代码，当一个消息被分发到worker之后，它会立即从内存中删掉。在这种情况下，如果一个worker没有正确的执行完一个消息，那么这个消息就丢失了。

当然，我们不希望丢失掉任何的tasks，如果执行该task的worker挂掉了，那么应该将这个task分发给其他的worker去执行。

为了确保一个消息永远都不会丢失，RabbitMQ引入了消息ACK的机制。当worker执行完了一个task之后，就会发送一个消息给RabbitMQ，说明某个消息已经被执行完毕了，RabbitMQ可以将这个消息删除了。

如果worker挂掉了，那么它就不会发送ACK了，RabbitMQ就知道某个消息没有完整的被执行，然后会重新将这个task发送给其他的worker，这就可以保证消息不会丢失。（但是，如果task执行完了，发送了ACK，由于某种原因，ACK没有成功的抵达RabbitMQ，那么这个task会被重新执行一次。）

在RabbitMQ中，没有消息延迟的概念，task只有在到某个worker的连接断掉之后，才会重发。即使一个task执行了很长很长的时候，也是正常的。

默认情况下，ACK是打开的，也是可以设置的。

有一种常见的错误：在worker执行完了之后，没有返回ACK，那么RabbitMQ会不断的重发消息。但是由于消息都没有返回ACK，那么RabbitMQ会不断的吃内存，将消息保存起来。对于这种情况，可以通过使用rabbitmqctl工具来查看messages_unacknowledged字段：

```
$ sudo rabbitmqctl list_queues name messages_ready messages_unacknowledged
Listing queues ...
hello    0       0
...done.
```

#####2.3 Message durability（消息持久）
上一节讲到如何保证在worker挂掉的时候，不让消息丢失，但是如何保证RabbitMQ挂掉的时候，不丢失消息呢？那么消息就不能只保存在内存了，必须持久化。

为了保证在RabbitMQ挂掉的时候，消息不丢失，需要做两件事情：queue和messages都是持久化的。

首先要保证RabbitMQ不会丢失Queue，指定durable参数：

```
channel.queue_declare(queue='task_queue', durable=True)
```

RabbitMQ不允许使用不同的参数来重定义已经存在的Queue，如果这么做，会返回一个error。所以在上面的代码中，如果Queue "hello"已经存在的话，这样是没有用的，必须指定另外一个Queue名称。

指定了 durable=True 之后，即使RabbitMQ重启，Queue也不会丢失了。

其次，我们需要保证将我们的message标记为持久的了，通过指定参数delivery_mode = 2：

```
channel.basic_publish(exchange='',
                      routing_key="task_queue",
                      body=message,
                      properties=pika.BasicProperties(
                         delivery_mode = 2, # make message persistent
                      ))
```

注意：
即使通过指定参数来保证保存message消息到disk，从而不会丢失，但是总有一个时刻：RabbitMQ刚刚接手了一个消息，但是还没有保存到disk。__也就是，RabbitMQ并不能保存对每个消息执行fsync。这个持久化的保证并不强大，但是总比简单的task queue要好一点。__如果需要更强大的持久化保证，只能wrap它的代码。

```
fsync：同步内存中所有已修改的文件数据到储存设备。
[详细](http://baike.baidu.com/view/8092902.htm)
```

#####2.4 Fair dispatch（公平分发）
有些时候，上面的轮训分发并不能完全按照我们想象的来工作，比如：有两个worker，所有奇数的消息都是耗时的，偶数的消息都是不耗时的，那么所有耗时的消息都会被分发到worker-1上，所有不耗时的消息都会被分发到worker-2上。但是RabbitMQ什么都不知道，只能这么简单的分发消息，而并没有考虑某个Worker上UnACK的消息的个数。

可以通过如下设置来解决这个问题：

```
channel.basic_qos(prefetch_count=1)
```
这个参数告诉RabbitMQ，不要在同一时刻向同一个worker分发多余一个的消息，也就是说，在接受到之前的task的ACK之前，不要再分发消息给worker。

__当心Queue的大小：如果所有的Queue都busy，那么Queue就会不断变长，要么一直盯着，要么增加更多的worker，要么使用一些其他的策略。
__

#####2.5 完整代码
[官方网站](http://www.rabbitmq.com/tutorials/tutorial-two-python.html)

####3 订阅发布
在前面的模式中，每个消息只会发送到一个worker。在这里的“订阅发布”模式中，会发送一个消息给多个consumer。

#####3.1 Exchanges
在前面的部分中，只是介绍了从一个单独的Queue来接受消息，这里会介绍RabbitMQ的完整的消息模型。

{% img https://dl.dropbox.com/u/99113526/blog.bd17kaka.net/rabbitmq-2.png %}

在RabbitMQ中，producer永远不会直接将消息发送给Queue，实际上Producer甚至并不知道一个消息会被发送到一个Queue上。Producer只是将消息发送到exchange上。exchange一方面接收消息，一方面将消息推送到Queue上。Exchange必须知道如何处理每个接收到的消息：附加到一个Queue上？附加到多个Queue上？还是忽略之。

有很多种可用的exchange：direct, topic, headers and fanout。本节，主要介绍fanout。创建一个fanout类型的exchange：

```
channel.exchange_declare(exchange='logs',
                         type='fanout')
```

fanout类型的exchange的作用很简单，就是将它接收到得所有消息，分发到每一个它所知道的Queue。

然后就可以将消息发送到“logs”这个exchange：

```
channel.basic_publish(exchange='logs',
                      routing_key='',
                      body=message)
```

#####3.2 临时Queue
我们有时只关注当前的消息，而并不关注之前的消息，或者希望在consumer断开与RabbitMQ的连接之后，不保存Queue中的消息，那么可以使用临时Queue。要做到这点，需要两点：

* 在server端创建一个使用随机Queue名称的channel；
* 客户端在声明Queue的时候，加上exclusive=true参数；

```
(客户端)
result = channel.queue_declare(exclusive=True)
```

#####3.3 绑定
接下来，就需要绑定：

```
(客户端)
channel.queue_bind(exchange='logs',
                   queue=result.method.queue)
```

####4 Routing
这一节介绍的模型可以只将所有消息的子集发送到某个指定的Queue。比如在日志系统中，可以将error消息和warning消息发送到两个不一样的Queue。

在bing过程中，可以指定一个routing_key参数：

```
channel.queue_bind(exchange=exchange_name,
                   queue=queue_name,
                   routing_key='black')
```

routing_key在有的类型的exchange中是被忽视的，比如在前面的fanout模型中，是被忽略的。

#####4.1 Direct exchange
{% img https://dl.dropbox.com/u/99113526/blog.bd17kaka.net/rabbitmq-4.png %}

在这个图中可以看到，exchange和两个Queue绑定，第一个Queue和routing_key为orange的消息绑定，第二个Queue和routing_key为black和green的Queue绑定。

消息根据它们的routing_key被分发到不同的Queue。

也可以将一个routing_key绑定到多个Queue，如果绑定到所有的Queue的话，那么这种模型和fanout exchange就是一样的了。

#####4.2 producer分发消息

```
channel.exchange_declare(exchange='direct_logs',
                         type='direct')

channel.basic_publish(exchange='direct_logs',
                      routing_key=severity,
                      body=message)
```

#####4.3 consumer消费消息

```
result = channel.queue_declare(exclusive=True)queue_name = result.method.queue

for severity in severities:
    channel.queue_bind(exchange='direct_logs',
                       queue=queue_name,
                       routing_key=severity)
```



continue...